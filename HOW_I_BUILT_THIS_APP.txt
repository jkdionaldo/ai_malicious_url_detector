AI-BASED MALICIOUS URL DETECTION SYSTEM
Build Notes (from scratch, student-friendly)

Goal (what the app does)
1) Load a malicious-URL dataset from data/ (CSV)
2) Extract simple lexical features from each URL (length, dots, hyphens, etc.)
3) Train a Random Forest model and (optionally) print a Classification Report
4) Stay open in a loop so you can paste URLs continuously
5) For each URL: predict Safe/Malicious + show a defanged (non-clickable) version
6) Support packaging into a single Windows .exe using PyInstaller


A) What you need installed (one-time setup)
1) Install Python
   - Recommended: Python 3.10+
   - Confirm it works:
     - python --version

2) (Recommended) Create/activate a virtual environment (optional but clean)
   - python -m venv .venv
   - .venv\Scripts\activate

3) Install project dependencies
   - From the project folder (ai_malicious_url_detection):
     - pip install -r requirements.txt

What requirements.txt includes
- pandas: read CSV + manipulate data
- scikit-learn: train RandomForest + evaluate model
- rich: nicer terminal dashboard UI
- joblib: save/load the trained model quickly (caching)


B) Project structure (what each folder/file is for)
ai_malicious_url_detection/
  README.md                    -> how to run + how to build EXE
  requirements.txt             -> Python dependencies
  src/
    malicious_url_detection.py -> the app (training + UI + classification + defanging)
  data/
    malicious_url.csv          -> (you add this) your real dataset
    sample_urls.csv            -> small sample dataset included
    README_DATASET.md          -> dataset notes


C) Dataset: how it is loaded (no --csv required)
1) The app tries these default paths in order:
   - data/malicious_url.csv
   - data/sample_urls.csv

2) I set it up so I do NOT need to pass --csv every time.
   - I can still override with --csv if I want.

3) Column detection
   - Many Kaggle datasets use columns like:
     - url + type  (benign/phishing/malware/...)
     - url + label (0/1)
   - The app auto-detects common URL/label column names.


D) How the “lexical feature extraction” works
The model does NOT visit the website.
It only looks at the URL string itself (fast and explainable).

Examples of features extracted from each URL:
- length: long URLs can hide suspicious content
- dot_count: many dots can indicate deceptive subdomains
- hyphen_count: hyphens are common in lookalike/phishing domains
- digit_count + digit_ratio: random digits can appear in auto-generated malicious URLs
- special characters like @, %, ?, &, =: often used for obfuscation or redirects
- has_ip: IP-address URLs can be suspicious
- uses_https: helpful signal (not a guarantee of safety)
- suspicious_kw_count: presence of words like login/verify/update/secure
- is_shortened: detects common URL shorteners

The function doing this is:
- extract_lexical_features(url)


E) How the AI/ML model is trained
1) Convert URLs into a numeric feature table (X)
2) Convert labels into binary targets (y)
   - Safe = 0
   - Malicious = 1
3) Split into train/test sets (so we can evaluate fairly)
4) Train RandomForestClassifier
   - Random forests are strong baselines and easy to explain


F) Model evaluation (required for grading)
To print Precision/Recall/F1, run:
- python src\malicious_url_detection.py --evaluate

This prints a "Classification Report (Required)".

Note: the included sample dataset is tiny, so its report is not meaningful.
For your final demo/report, use a real Kaggle dataset for realistic metrics.


G) How the mitigation loop works (paste URLs continuously)
1) App starts and shows a dashboard:
   - System Status: AI Model Loaded
   - Security Warning: Caution: Do not click suspicious links.

2) It then waits for input:
   - URL> <paste here>

3) For each URL it does:
   a) Predict label + confidence using the trained model
   b) Defang the URL so it’s safer to share in reports


H) URL defanging (sanitization)
Why: Security analysts share URLs in reports without making them clickable.

Rules used (required):
- http://  -> hxxp://
- https:// -> hxxps://
- .        -> [.]  (every dot)

Function:
- defang_url(url)

Example:
Input:  http://google.com@evil.com/path
Output: hxxp://google[.]com@evil[.]com/path


I) Model caching (so the app loads fast)
- After training, the model is saved with joblib in a per-user folder:
  C:\Users\<YOU>\AppData\Local\ai_malicious_url_detection\url_rf_model.joblib
- Next runs load the cached model instead of retraining.
- You can force retraining with:
  - python src\malicious_url_detection.py --retrain --evaluate


J) Turn it into a single Windows .exe (PyInstaller)
1) Install PyInstaller
   - pip install pyinstaller

2) Build (run from the project root folder)
   - pyinstaller --onefile --name MaliciousURLDetector --add-data "data;data" src\malicious_url_detection.py

3) Result
   - dist\MaliciousURLDetector.exe

4) Submit as a single file (no folder)
   - I copy the EXE to the project root so I can send just one file:
     - Copy-Item -Force .\dist\MaliciousURLDetector.exe .\MaliciousURLDetector.exe

Why we use --add-data
- It bundles the data/ folder (so the app can find data/sample_urls.csv or data/malicious_url.csv).


K) How to explain the system in a presentation (simple talk track)
1) “I only analyze the URL text (lexical features), not the website content.”
2) “I train a Random Forest using those lexical features.”
3) “I evaluate using Precision/Recall/F1 (classification report).”
4) “I mitigate risk by defanging suspicious links for safe reporting.”
5) “I package it as an EXE so it runs like a standalone tool.”


J2) Clean build (recommended)
Before running PyInstaller, I clear old build output to avoid stale artifacts.

PowerShell:
- Remove-Item -Recurse -Force .\build, .\dist -ErrorAction SilentlyContinue
- Remove-Item -Force .\MaliciousURLDetector.spec -ErrorAction SilentlyContinue

CMD:
- if exist build rmdir /s /q build
- if exist dist rmdir /s /q dist
- if exist MaliciousURLDetector.spec del /q MaliciousURLDetector.spec


J3) Console mode vs hidden window
- Console mode (recommended): shows the Rich dashboard in the terminal.
   - pyinstaller --onefile --name MaliciousURLDetector --add-data "data;data" src\malicious_url_detection.py

- Hidden window (optional): hides the terminal window.
   NOTE: This disables the interactive dashboard display, so I keep console mode enabled for my class demo.
   - pyinstaller --onefile --noconsole --name MaliciousURLDetector --add-data "data;data" src\malicious_url_detection.py
